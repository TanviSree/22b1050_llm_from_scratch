{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1hn4X6JvbFj9DRSbZY5WaAvFMweLiEASh",
      "authorship_tag": "ABX9TyPc2M66nwx96N180aAAwacm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TanviSree/22b1050_llm_from_scratch/blob/main/Chapter5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p6tl53vS1Lj7"
      },
      "outputs": [],
      "source": [
        "from importlib.metadata import version\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c4b5dc1",
        "outputId": "26639367-f53e-4805-9c6f-3ab28bb10b9e"
      },
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# 1. Define a list of the file paths for the .ipynb files you want to convert.\n",
        "# Replace these with the actual paths to your .ipynb files\n",
        "ipynb_files = [\n",
        "    '/content/drive/MyDrive/Colab Notebooks/Chapter4.ipynb',\n",
        "    '/content/drive/MyDrive/Colab Notebooks/chapter3.ipynb',\n",
        "    '/content/drive/MyDrive/Colab Notebooks/chapter2.ipynb'\n",
        "    # Add more file paths as needed\n",
        "]\n",
        "\n",
        "# 2. Specify the desired name for the output .py file.\n",
        "output_py_file = 'converted_code.py'\n",
        "\n",
        "# Ensure the output file is empty or create it if it doesn't exist\n",
        "with open(output_py_file, 'w') as f:\n",
        "    f.write('')\n",
        "\n",
        "# 3. Iterate through each .ipynb file in the list.\n",
        "for ipynb_file in ipynb_files:\n",
        "    print(f\"Processing {ipynb_file}...\")\n",
        "    try:\n",
        "        # 4. For each .ipynb file, read its content using a suitable library (like json).\n",
        "        with open(ipynb_file, 'r', encoding='utf-8') as f:\n",
        "            notebook_content = json.load(f)\n",
        "\n",
        "        # Check if 'cells' key exists and is a list\n",
        "        if 'cells' not in notebook_content or not isinstance(notebook_content['cells'], list):\n",
        "            print(f\"Warning: '{ipynb_file}' does not have a valid 'cells' structure. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        # 5. Extract the code cells from the notebook structure.\n",
        "        # 6. Write the extracted code into the output .py file, ensuring proper formatting and separation.\n",
        "        with open(output_py_file, 'a', encoding='utf-8') as f:\n",
        "            f.write(f\"# Code extracted from {os.path.basename(ipynb_file)}\\n\\n\")\n",
        "            for i, cell in enumerate(notebook_content['cells']):\n",
        "                if cell['cell_type'] == 'code':\n",
        "                    # 7. Include comments indicating the original notebook and cell number.\n",
        "                    f.write(f\"# Cell {i}\\n\")\n",
        "                    # Join the source list into a single string and write it\n",
        "                    f.write(\"\".join(cell['source']) + \"\\n\\n\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at {ipynb_file}. Skipping.\")\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Error: Could not decode JSON from {ipynb_file}. Skipping.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred while processing {ipynb_file}: {e}. Skipping.\")\n",
        "\n",
        "print(f\"Code extraction complete. Output saved to {output_py_file}\")\n",
        "\n",
        "# Optional: Display the content of the generated .py file\n",
        "# with open(output_py_file, 'r', encoding='utf-8') as f:\n",
        "#     print(\"\\n--- Content of generated .py file ---\")\n",
        "#     print(f.read())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/drive/MyDrive/Colab Notebooks/Chapter4.ipynb...\n",
            "Processing /content/drive/MyDrive/Colab Notebooks/chapter3.ipynb...\n",
            "Processing /content/drive/MyDrive/Colab Notebooks/chapter2.ipynb...\n",
            "Code extraction complete. Output saved to converted_code.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import converted_code1 as cd\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,   # Vocabulary size\n",
        "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
        "    \"emb_dim\": 768,        # Embedding dimension\n",
        "    \"n_heads\": 12,         # Number of attention heads\n",
        "    \"n_layers\": 12,        # Number of layers\n",
        "    \"drop_rate\": 0.1,      # Dropout rate\n",
        "    \"qkv_bias\": False      # Query-key-value bias\n",
        "}\n",
        "torch.manual_seed(123)\n",
        "model = cd.GPTModel(GPT_CONFIG_124M)\n",
        "model.eval();"
      ],
      "metadata": {
        "id": "ZJaBkXguOe9T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0)\n",
        "    return tokenizer.decode(flat.tolist())\n",
        "\n",
        "start_context = \"This is the beggining of\"\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = cd.generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(start_context, tokenizer),\n",
        "    max_new_tokens=10,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYP69X31Rgp1",
        "outputId": "9f837eec-1e2f-4e9b-ea00-d8ca16921bef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " This is the beggining of List debunk ageingLocated bear confidently doctor Sas sang feces\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
        "                       [40,    1107, 588]])   #  \"I really like\"]\n",
        "\n",
        "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
        "                        [1107,  588, 11311]]) #  \" really like chocolate\"]\n",
        "with torch.no_grad():\n",
        "  logits = model(inputs)\n",
        "\n",
        "probas = torch.softmax(logits, dim=-1)\n",
        "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "text_idx = 0\n",
        "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"Text 1:\", target_probas_1)\n",
        "\n",
        "text_idx = 1\n",
        "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"Text 2:\", target_probas_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zrv9bx8lR0Jo",
        "outputId": "7e890910-76c2-4e8b-a445-a9260ddd7e37"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 1: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
            "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute logarithm of all token probabilities\n",
        "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
        "print(log_probas)\n",
        "avg_log_probas = torch.mean(log_probas)\n",
        "print(avg_log_probas)\n",
        "neg_avg_log_probas = avg_log_probas * -1\n",
        "print(neg_avg_log_probas)\n",
        "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
        "print(\"Logits shape:\", logits.shape)\n",
        "\n",
        "# Targets have shape (batch_size, num_tokens)\n",
        "print(\"Targets shape:\", targets.shape)\n",
        "logits_flat = logits.flatten(0, 1)\n",
        "targets_flat = targets.flatten()\n",
        "\n",
        "print(\"Flattened logits:\", logits_flat.shape)\n",
        "print(\"Flattened targets:\", targets_flat.shape)\n",
        "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
        "print(loss)\n",
        "perplexity = torch.exp(loss)\n",
        "print(perplexity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITLrghY7ctop",
        "outputId": "debcdf8f-c3d7-4e4d-a206-0ca353b83328"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n",
            "tensor(-10.7940)\n",
            "tensor(10.7940)\n",
            "Logits shape: torch.Size([2, 3, 50257])\n",
            "Targets shape: torch.Size([2, 3])\n",
            "Flattened logits: torch.Size([6, 50257])\n",
            "Flattened targets: torch.Size([6])\n",
            "tensor(10.7940)\n",
            "tensor(48725.8203)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and Validation Set Losses\n"
      ],
      "metadata": {
        "id": "p30YsxbAeAj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "file_path = \"the-verdict.txt\"\n",
        "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "        text_data = response.read().decode('utf-8')\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(text_data)\n",
        "else:\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        text_data = file.read()"
      ],
      "metadata": {
        "id": "heko80fveD8B"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(text_data))\n",
        "train_data = text_data[:split_idx]\n",
        "val_data = text_data[split_idx:]\n",
        "\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = cd.create_dataloader_v1(\n",
        "    train_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_loader = cd.create_dataloader_v1(\n",
        "    val_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "IsZG6mpWeHME"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_tokens = len(tokenizer.encode(text_data))\n",
        "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
        "    print(\"Not enough tokens for the training loader. \"\n",
        "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
        "          \"increase the `training_ratio`\")\n",
        "\n",
        "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
        "    print(\"Not enough tokens for the validation loader. \"\n",
        "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
        "          \"decrease the `training_ratio`\")"
      ],
      "metadata": {
        "id": "YCcMiIFeeSJ9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ],
      "metadata": {
        "id": "EdmH0RA0eevb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, model, device)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device)\n",
        "\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0Ptwne5em5v",
        "outputId": "2efec56d-f617-475b-c066-6a041a76e288"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 10.98758347829183\n",
            "Validation loss: 10.98110580444336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training LLM"
      ],
      "metadata": {
        "id": "Pat47DjadFCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "\n",
        "\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = cd.generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "tq4CeWK3dDUs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note:\n",
        "# Uncomment the following code to calculate the execution time\n",
        "# import time\n",
        "# start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = cd.GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# Note:\n",
        "# Uncomment the following code to show the execution time\n",
        "# end_time = time.time()\n",
        "# execution_time_minutes = (end_time - start_time) / 60\n",
        "# print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mis0nnMqdRLr",
        "outputId": "5901e610-b328-42c3-8830-f660ef36d8d6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 9.783, Val loss 9.927\n",
            "Ep 1 (Step 000005): Train loss 7.985, Val loss 8.335\n",
            "Every effort moves you,,,,,,,,,,,,.                                     \n",
            "Ep 2 (Step 000010): Train loss 6.753, Val loss 7.048\n",
            "Ep 2 (Step 000015): Train loss 6.114, Val loss 6.573\n",
            "Every effort moves you, and,, and, and,,,,, and, and,,,,,,,,,,,,,, and,,,, and,, and,,,,, and,,,,,,\n",
            "Ep 3 (Step 000020): Train loss 5.525, Val loss 6.490\n",
            "Ep 3 (Step 000025): Train loss 5.324, Val loss 6.387\n",
            "Every effort moves you, and to the picture.                      \"I, and the of the of the's the honour, and, and I had been, and I\n",
            "Ep 4 (Step 000030): Train loss 4.761, Val loss 6.360\n",
            "Ep 4 (Step 000035): Train loss 4.461, Val loss 6.258\n",
            "Every effort moves you of the to the picture--as of the picture--as I had been \" it was his \" I was the     \"I was his I had been the his pictures--and it the picture and I had been the picture of\n",
            "Ep 5 (Step 000040): Train loss 3.833, Val loss 6.196\n",
            "Every effort moves you know the \"Oh, and he was not the fact by his last word.         \"I was.      \"Oh, I felt a little a little the    \n",
            "Ep 6 (Step 000045): Train loss 3.352, Val loss 6.139\n",
            "Ep 6 (Step 000050): Train loss 2.861, Val loss 6.112\n",
            "Every effort moves you know; and my dear, and he was not the fact with a little of the house of the fact of the fact, and.                       \n",
            "Ep 7 (Step 000055): Train loss 2.347, Val loss 6.138\n",
            "Ep 7 (Step 000060): Train loss 2.084, Val loss 6.179\n",
            "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I looked--as of the fact, and I felt him--his back his head to the donkey. \"Oh, and_--because he had always _\n",
            "Ep 8 (Step 000065): Train loss 1.521, Val loss 6.176\n",
            "Ep 8 (Step 000070): Train loss 1.272, Val loss 6.178\n",
            "Every effort moves you?\" \"I didn't bear the picture--I told me.  \"I looked up, and went on groping and Mrs. I was back the head to look up at the honour being _mine_--because he was when I\n",
            "Ep 9 (Step 000075): Train loss 1.000, Val loss 6.277\n",
            "Ep 9 (Step 000080): Train loss 0.718, Val loss 6.281\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
            "Ep 10 (Step 000085): Train loss 0.506, Val loss 6.325\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to the donkey again. I saw that, and down the room, when I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(\"loss-plot.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "6eDp7ovmnAgi",
        "outputId": "d0561db8-c56b-4dbd-ecd5-2488fcd147c7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reduce Randomness"
      ],
      "metadata": {
        "id": "FZmrTD92KPxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(\"cpu\")\n",
        "model.eval()\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
        "    max_new_tokens=25,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "id": "S0BUJFARKPat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {\n",
        "    \"closer\": 0,\n",
        "    \"every\": 1,\n",
        "    \"effort\": 2,\n",
        "    \"forward\": 3,\n",
        "    \"inches\": 4,\n",
        "    \"moves\": 5,\n",
        "    \"pizza\": 6,\n",
        "    \"toward\": 7,\n",
        "    \"you\": 8,\n",
        "}\n",
        "\n",
        "inverse_vocab = {v: k for k, v in vocab.items()}\n",
        "\n",
        "# Suppose input is \"every effort moves you\", and the LLM\n",
        "# returns the following logits for the next token:\n",
        "next_token_logits = torch.tensor(\n",
        "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
        ")\n",
        "\n",
        "probas = torch.softmax(next_token_logits, dim=0)\n",
        "next_token_id = torch.argmax(probas).item()\n",
        "\n",
        "# The next generated token is then as follows:\n",
        "print(inverse_vocab[next_token_id])"
      ],
      "metadata": {
        "id": "T9aOujjzKZxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
        "print(inverse_vocab[next_token_id])"
      ],
      "metadata": {
        "id": "0p0TCC-JKn5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_sampled_tokens(probas):\n",
        "    torch.manual_seed(123) # Manual seed for reproducibility\n",
        "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
        "    sampled_ids = torch.bincount(torch.tensor(sample), minlength=len(probas))\n",
        "    for i, freq in enumerate(sampled_ids):\n",
        "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
        "\n",
        "print_sampled_tokens(probas)"
      ],
      "metadata": {
        "id": "-L2wp3XaKp_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_with_temperature(logits, temperature):\n",
        "    scaled_logits = logits / temperature\n",
        "    return torch.softmax(scaled_logits, dim=0)\n",
        "\n",
        "# Temperature values\n",
        "temperatures = [1, 0.1, 5]  # Original, higher confidence, and lower confidence\n",
        "\n",
        "# Calculate scaled probabilities\n",
        "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
      ],
      "metadata": {
        "id": "ubqLPafMK7Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting\n",
        "x = torch.arange(len(vocab))\n",
        "bar_width = 0.15\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5, 3))\n",
        "for i, T in enumerate(temperatures):\n",
        "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
        "\n",
        "ax.set_ylabel('Probability')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"temperature-plot.pdf\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x9NtKOB8K9O-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "top k sampling"
      ],
      "metadata": {
        "id": "TCUwrVfsLg32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_k = 3\n",
        "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
        "\n",
        "print(\"Top logits:\", top_logits)\n",
        "print(\"Top positions:\", top_pos)"
      ],
      "metadata": {
        "id": "RcCnOn8pLiok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_logits = torch.where(\n",
        "    condition=next_token_logits < top_logits[-1],\n",
        "    input=torch.tensor(float(\"-inf\")),\n",
        "    other=next_token_logits\n",
        ")\n",
        "\n",
        "print(new_logits)\n",
        "topk_probas = torch.softmax(new_logits, dim=0)\n",
        "print(topk_probas)"
      ],
      "metadata": {
        "id": "QUiZ99OMLmZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "\n",
        "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # New: Filter logits with top_k sampling\n",
        "        if top_k is not None:\n",
        "            # Keep only top_k values\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        # New: Apply temperature scaling\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "\n",
        "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
        "            break\n",
        "\n",
        "        # Same as before: append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "QkSJRcs6LsOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
        "    top_k=25,\n",
        "    temperature=1.4\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "id": "k1BX4VydLvFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loading model weights and saving them in pytorch\n"
      ],
      "metadata": {
        "id": "ajLmiGVfLv5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.load_state_dict(torch.load(\"model.pth\", map_location=device, weights_only=True))\n",
        "model.eval();\n",
        "torch.save({\n",
        "    \"model_state_dict\": model.state_dict(),\n",
        "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "    },\n",
        "    \"model_and_optimizer.pth\"\n",
        ")\n",
        "checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n",
        "\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "model.train();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "rt4SkCs8L0jG",
        "outputId": "6b77d41b-b580-46f7-9f96-fc98b7f683f9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'GPTModel' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-16-2697057193.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPTModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGPT_CONFIG_124M\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model.pth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'GPTModel' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "loading weights from openAI"
      ],
      "metadata": {
        "id": "VDf_9o6fL_vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"gpt2-small-124M.pth\"\n",
        "# file_name = \"gpt2-medium-355M.pth\"\n",
        "# file_name = \"gpt2-large-774M.pth\"\n",
        "# file_name = \"gpt2-xl-1558M.pth\"\n",
        "\n",
        "url = f\"https://huggingface.co/rasbt/gpt2-from-scratch-pytorch/resolve/main/{file_name}\"\n",
        "\n",
        "if not os.path.exists(file_name):\n",
        "    urllib.request.urlretrieve(url, file_name)\n",
        "    print(f\"Downloaded to {file_name}\")\n",
        "\n",
        "gpt = GPTModel(BASE_CONFIG)\n",
        "gpt.load_state_dict(torch.load(file_name, weights_only=True))\n",
        "gpt.eval()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "gpt.to(device);\n",
        "\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "token_ids = generate(\n",
        "    model=gpt,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
        "    max_new_tokens=25,\n",
        "    context_size=NEW_CONFIG[\"context_length\"],\n",
        "    top_k=50,\n",
        "    temperature=1.5\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "id": "KY60YSKsMBwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt_download import download_and_load_gpt2"
      ],
      "metadata": {
        "id": "fCuB6wrZMIU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")\n",
        "print(\"Settings:\", settings)\n",
        "print(\"Parameter dictionary keys:\", params.keys())\n",
        "print(params[\"wte\"])\n",
        "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
      ],
      "metadata": {
        "id": "_iqE4u6FMMFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "# Copy the base configuration and update with specific model settings\n",
        "model_name = \"gpt2-small (124M)\"  # Example model name\n",
        "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
        "NEW_CONFIG.update(model_configs[model_name])\n",
        "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
        "gpt = GPTModel(NEW_CONFIG)\n",
        "gpt.eval();"
      ],
      "metadata": {
        "id": "F7RSRwynMWCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))"
      ],
      "metadata": {
        "id": "sohC9_H-MYQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        q_w, k_w, v_w = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        q_b, k_b, v_b = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(\n",
        "            gpt.trf_blocks[b].norm1.scale,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(\n",
        "            gpt.trf_blocks[b].norm1.shift,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(\n",
        "            gpt.trf_blocks[b].norm2.scale,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(\n",
        "            gpt.trf_blocks[b].norm2.shift,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
        "\n",
        "\n",
        "load_weights_into_gpt(gpt, params)\n",
        "gpt.to(device);"
      ],
      "metadata": {
        "id": "twHIWwCPMddY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "token_ids = generate(\n",
        "    model=gpt,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
        "    max_new_tokens=25,\n",
        "    context_size=NEW_CONFIG[\"context_length\"],\n",
        "    top_k=50,\n",
        "    temperature=1.5\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "id": "ICvGb-R8Mne_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}